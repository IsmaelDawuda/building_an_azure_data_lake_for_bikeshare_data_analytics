{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e60c1c45-6116-4356-8df9-3a39c2c53e72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5210b65-9747-47a5-aa5e-02263b5b6f60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"bikeshare\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c9e4652-ede6-451c-84ba-6aa1f3b2963f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Loading and Writing Data to Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c5c675b-e178-4df2-9c61-45f445a86f8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "[ spark.sql(f\"DROP TABLE IF EXISTS {table}\") for table in ['payments', 'trips', 'riders', 'stations', 'trip_dates', 'payment_dates'] ]\n",
    "\n",
    "payment_df = spark.read.format('csv').option('sep', ',').load('/FileStore/payments.csv')\n",
    "trip_df = spark.read.format('csv').option('sep', ',').load('/FileStore/trips.csv')\n",
    "rider_df = spark.read.format('csv').option('sep', ',').load('/FileStore/riders.csv')\n",
    "station_df = spark.read.format('csv').option('sep', ',').load('/FileStore/stations.csv')\n",
    "\n",
    "\n",
    "dataframes = {\n",
    "    'payments': payment_df,\n",
    "    'trips': trip_df,\n",
    "    'riders': rider_df,\n",
    "    'stations': station_df\n",
    "}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    df.write.format('delta').mode('overwrite').saveAsTable(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61f2986b-33ac-484b-9aa8-7a60e84a1ecf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "display raw data"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<h3>payments_table</h3>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<h3>payments_table</h3>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---+----------+---+----+\n",
       "_c0|       _c1|_c2| _c3|\n",
       "+---+----------+---+----+\n",
       "  1|2019-05-01|9.0|1000|\n",
       "  2|2019-06-01|9.0|1000|\n",
       "  3|2019-07-01|9.0|1000|\n",
       "  4|2019-08-01|9.0|1000|\n",
       "  5|2019-09-01|9.0|1000|\n",
       "  6|2019-10-01|9.0|1000|\n",
       "  7|2019-11-01|9.0|1000|\n",
       "  8|2019-12-01|9.0|1000|\n",
       "  9|2020-01-01|9.0|1000|\n",
       " 10|2020-02-01|9.0|1000|\n",
       " 11|2020-03-01|9.0|1000|\n",
       " 12|2020-04-01|9.0|1000|\n",
       " 13|2020-05-01|9.0|1000|\n",
       " 14|2020-06-01|9.0|1000|\n",
       " 15|2020-07-01|9.0|1000|\n",
       " 16|2020-08-01|9.0|1000|\n",
       " 17|2020-09-01|9.0|1000|\n",
       " 18|2020-10-01|9.0|1000|\n",
       " 19|2020-11-01|9.0|1000|\n",
       " 20|2020-12-01|9.0|1000|\n",
       "+---+----------+---+----+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+---+----------+---+----+\n|_c0|       _c1|_c2| _c3|\n+---+----------+---+----+\n|  1|2019-05-01|9.0|1000|\n|  2|2019-06-01|9.0|1000|\n|  3|2019-07-01|9.0|1000|\n|  4|2019-08-01|9.0|1000|\n|  5|2019-09-01|9.0|1000|\n|  6|2019-10-01|9.0|1000|\n|  7|2019-11-01|9.0|1000|\n|  8|2019-12-01|9.0|1000|\n|  9|2020-01-01|9.0|1000|\n| 10|2020-02-01|9.0|1000|\n| 11|2020-03-01|9.0|1000|\n| 12|2020-04-01|9.0|1000|\n| 13|2020-05-01|9.0|1000|\n| 14|2020-06-01|9.0|1000|\n| 15|2020-07-01|9.0|1000|\n| 16|2020-08-01|9.0|1000|\n| 17|2020-09-01|9.0|1000|\n| 18|2020-10-01|9.0|1000|\n| 19|2020-11-01|9.0|1000|\n| 20|2020-12-01|9.0|1000|\n+---+----------+---+----+\nonly showing top 20 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<h3>trips_table</h3>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<h3>trips_table</h3>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----------------+-------------+-------------------+-------------------+------------+------------+-----+\n",
       "             _c0|          _c1|                _c2|                _c3|         _c4|         _c5|  _c6|\n",
       "+----------------+-------------+-------------------+-------------------+------------+------------+-----+\n",
       "89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|         525|         660|71934|\n",
       "0FEFDE2603568365| classic_bike|2021-02-14 17:52:38|2021-02-14 18:12:09|         525|       16806|47854|\n",
       "E6159D746B2DBB91|electric_bike|2021-02-09 19:10:18|2021-02-09 19:19:10|KA1503000012|TA1305000029|70870|\n",
       "B32D3199F1C2E75B| classic_bike|2021-02-02 17:49:41|2021-02-02 17:54:06|         637|TA1305000034|58974|\n",
       "83E463F23575F4BF|electric_bike|2021-02-23 15:07:23|2021-02-23 15:22:37|       13216|TA1309000055|39608|\n",
       "BDAA7E3494E8D545|electric_bike|2021-02-24 15:43:33|2021-02-24 15:49:05|       18003|KP1705001026|36267|\n",
       "A772742351171257| classic_bike|2021-02-01 17:47:42|2021-02-01 17:48:33|KP1705001026|KP1705001026|50104|\n",
       "295476889D9B79F8| classic_bike|2021-02-11 18:33:53|2021-02-11 18:35:09|       18003|       18003|19618|\n",
       "362087194BA4CC9A| classic_bike|2021-02-27 15:13:39|2021-02-27 15:36:36|KP1705001026|KP1705001026|16732|\n",
       "21630F715038CCB0| classic_bike|2021-02-20 08:59:42|2021-02-20 09:17:04|KP1705001026|KP1705001026|57068|\n",
       "A977EB7FE7F5CD3A| classic_bike|2021-02-20 08:58:16|2021-02-20 08:58:41|KP1705001026|KP1705001026|32712|\n",
       "8B868B03D6753C2A| classic_bike|2021-02-20 16:45:11|2021-02-20 16:59:47|KP1705001026|KP1705001026|23227|\n",
       "BD331D658B9D2C31| classic_bike|2021-02-18 13:21:03|2021-02-18 13:25:20|         525|         520|73221|\n",
       "8DFEA9BAFE6BAA62| classic_bike|2021-02-26 17:40:05|2021-02-26 17:42:49|       13253|TA1309000050|22163|\n",
       "27BE9F6E67AFD86C| classic_bike|2021-02-06 14:40:25|2021-02-06 14:55:50|         525|       15578| 7566|\n",
       "9B790D47A0A0F7F1| classic_bike|2021-02-19 23:25:40|2021-02-20 00:10:00|KA1503000044|KA1504000142|71588|\n",
       "3C2DF72600B1DE6C| classic_bike|2021-02-18 23:20:10|2021-02-19 00:01:39|KA1503000044|KA1504000142|38661|\n",
       "48A8D07ED9C7065C| classic_bike|2021-02-20 23:35:29|2021-02-21 00:17:18|KA1503000044|KA1504000142|64751|\n",
       "BBFF2AAA0A3A1A26|electric_bike|2021-02-02 15:48:52|2021-02-02 16:03:40|KA1504000140|       17660|10721|\n",
       "030723CBA8CF05E7| classic_bike|2021-02-23 07:44:12|2021-02-23 07:48:57|TA1305000032|       15542|13281|\n",
       "+----------------+-------------+-------------------+-------------------+------------+------------+-----+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+----------------+-------------+-------------------+-------------------+------------+------------+-----+\n|             _c0|          _c1|                _c2|                _c3|         _c4|         _c5|  _c6|\n+----------------+-------------+-------------------+-------------------+------------+------------+-----+\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|         525|         660|71934|\n|0FEFDE2603568365| classic_bike|2021-02-14 17:52:38|2021-02-14 18:12:09|         525|       16806|47854|\n|E6159D746B2DBB91|electric_bike|2021-02-09 19:10:18|2021-02-09 19:19:10|KA1503000012|TA1305000029|70870|\n|B32D3199F1C2E75B| classic_bike|2021-02-02 17:49:41|2021-02-02 17:54:06|         637|TA1305000034|58974|\n|83E463F23575F4BF|electric_bike|2021-02-23 15:07:23|2021-02-23 15:22:37|       13216|TA1309000055|39608|\n|BDAA7E3494E8D545|electric_bike|2021-02-24 15:43:33|2021-02-24 15:49:05|       18003|KP1705001026|36267|\n|A772742351171257| classic_bike|2021-02-01 17:47:42|2021-02-01 17:48:33|KP1705001026|KP1705001026|50104|\n|295476889D9B79F8| classic_bike|2021-02-11 18:33:53|2021-02-11 18:35:09|       18003|       18003|19618|\n|362087194BA4CC9A| classic_bike|2021-02-27 15:13:39|2021-02-27 15:36:36|KP1705001026|KP1705001026|16732|\n|21630F715038CCB0| classic_bike|2021-02-20 08:59:42|2021-02-20 09:17:04|KP1705001026|KP1705001026|57068|\n|A977EB7FE7F5CD3A| classic_bike|2021-02-20 08:58:16|2021-02-20 08:58:41|KP1705001026|KP1705001026|32712|\n|8B868B03D6753C2A| classic_bike|2021-02-20 16:45:11|2021-02-20 16:59:47|KP1705001026|KP1705001026|23227|\n|BD331D658B9D2C31| classic_bike|2021-02-18 13:21:03|2021-02-18 13:25:20|         525|         520|73221|\n|8DFEA9BAFE6BAA62| classic_bike|2021-02-26 17:40:05|2021-02-26 17:42:49|       13253|TA1309000050|22163|\n|27BE9F6E67AFD86C| classic_bike|2021-02-06 14:40:25|2021-02-06 14:55:50|         525|       15578| 7566|\n|9B790D47A0A0F7F1| classic_bike|2021-02-19 23:25:40|2021-02-20 00:10:00|KA1503000044|KA1504000142|71588|\n|3C2DF72600B1DE6C| classic_bike|2021-02-18 23:20:10|2021-02-19 00:01:39|KA1503000044|KA1504000142|38661|\n|48A8D07ED9C7065C| classic_bike|2021-02-20 23:35:29|2021-02-21 00:17:18|KA1503000044|KA1504000142|64751|\n|BBFF2AAA0A3A1A26|electric_bike|2021-02-02 15:48:52|2021-02-02 16:03:40|KA1504000140|       17660|10721|\n|030723CBA8CF05E7| classic_bike|2021-02-23 07:44:12|2021-02-23 07:48:57|TA1305000032|       15542|13281|\n+----------------+-------------+-------------------+-------------------+------------+------------+-----+\nonly showing top 20 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<h3>riders_table</h3>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<h3>riders_table</h3>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----+-----------+---------+--------------------+----------+----------+----------+-----+\n",
       " _c0|        _c1|      _c2|                 _c3|       _c4|       _c5|       _c6|  _c7|\n",
       "+----+-----------+---------+--------------------+----------+----------+----------+-----+\n",
       "1000|      Diana|    Clark| 1200 Alyssa Squares|1989-02-13|2019-04-23|      null| True|\n",
       "1001|   Jennifer|    Smith|     397 Diana Ferry|1976-08-10|2019-11-01|2020-09-01| True|\n",
       "1002|      Karen|    Smith|644 Brittany Row ...|1998-08-10|2022-02-04|      null| True|\n",
       "1003|      Bryan|  Roberts|996 Dickerson Tur...|1999-03-29|2019-08-26|      null|False|\n",
       "1004|      Jesse|Middleton|7009 Nathan Expre...|1969-04-11|2019-09-14|      null| True|\n",
       "1005|  Christine|Rodriguez|224 Washington Mi...|1974-08-27|2020-03-24|      null|False|\n",
       "1006|     Alicia|   Taylor|   1137 Angela Locks|2004-01-30|2020-11-27|2021-12-01| True|\n",
       "1007|   Benjamin|Fernandez|   979 Phillips Ways|1988-01-11|2016-12-11|      null|False|\n",
       "1008|       John| Crawford|    7691 Evans Court|1987-02-21|2021-03-28|2021-07-01| True|\n",
       "1009|   Victoria|   Ritter|9922 Jim Crest Ap...|1981-02-07|2020-06-12|2021-11-01| True|\n",
       "1010|      Tracy|   Austin|    92973 Mary Ville|1996-04-07|2019-12-27|      null| True|\n",
       "1011|    Jessica|    Mcgee|950 Grimes Burg A...|1984-12-29|2017-05-20|      null| True|\n",
       "1012|    Heather|   Fisher|65532 Davis Sprin...|1980-10-20|2021-10-16|      null| True|\n",
       "1013|    Timothy|    Jones| 7757 Johnston Roads|1985-07-10|2020-12-28|2021-11-01| True|\n",
       "1014|   Jennifer|   Martin|   501 Arellano Land|1989-12-04|2017-11-24|      null| True|\n",
       "1015|Christopher|    Silva|3710 Rodriguez Gl...|2001-07-25|2017-07-10|      null| True|\n",
       "1016|     Andrew|    Jones|  72226 Casey Square|1991-12-13|2022-02-02|      null| True|\n",
       "1017|    William|   Lawson| 40395 Terrell Parks|1981-04-17|2019-03-11|      null| True|\n",
       "1018|     Shelly|   Briggs|   3514 Leslie Vista|1986-09-02|2021-07-25|      null|False|\n",
       "1019|       Tina|   Garcia|00348 Brandi Park...|1997-05-03|2021-07-10|2022-01-01|False|\n",
       "+----+-----------+---------+--------------------+----------+----------+----------+-----+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+----+-----------+---------+--------------------+----------+----------+----------+-----+\n| _c0|        _c1|      _c2|                 _c3|       _c4|       _c5|       _c6|  _c7|\n+----+-----------+---------+--------------------+----------+----------+----------+-----+\n|1000|      Diana|    Clark| 1200 Alyssa Squares|1989-02-13|2019-04-23|      null| True|\n|1001|   Jennifer|    Smith|     397 Diana Ferry|1976-08-10|2019-11-01|2020-09-01| True|\n|1002|      Karen|    Smith|644 Brittany Row ...|1998-08-10|2022-02-04|      null| True|\n|1003|      Bryan|  Roberts|996 Dickerson Tur...|1999-03-29|2019-08-26|      null|False|\n|1004|      Jesse|Middleton|7009 Nathan Expre...|1969-04-11|2019-09-14|      null| True|\n|1005|  Christine|Rodriguez|224 Washington Mi...|1974-08-27|2020-03-24|      null|False|\n|1006|     Alicia|   Taylor|   1137 Angela Locks|2004-01-30|2020-11-27|2021-12-01| True|\n|1007|   Benjamin|Fernandez|   979 Phillips Ways|1988-01-11|2016-12-11|      null|False|\n|1008|       John| Crawford|    7691 Evans Court|1987-02-21|2021-03-28|2021-07-01| True|\n|1009|   Victoria|   Ritter|9922 Jim Crest Ap...|1981-02-07|2020-06-12|2021-11-01| True|\n|1010|      Tracy|   Austin|    92973 Mary Ville|1996-04-07|2019-12-27|      null| True|\n|1011|    Jessica|    Mcgee|950 Grimes Burg A...|1984-12-29|2017-05-20|      null| True|\n|1012|    Heather|   Fisher|65532 Davis Sprin...|1980-10-20|2021-10-16|      null| True|\n|1013|    Timothy|    Jones| 7757 Johnston Roads|1985-07-10|2020-12-28|2021-11-01| True|\n|1014|   Jennifer|   Martin|   501 Arellano Land|1989-12-04|2017-11-24|      null| True|\n|1015|Christopher|    Silva|3710 Rodriguez Gl...|2001-07-25|2017-07-10|      null| True|\n|1016|     Andrew|    Jones|  72226 Casey Square|1991-12-13|2022-02-02|      null| True|\n|1017|    William|   Lawson| 40395 Terrell Parks|1981-04-17|2019-03-11|      null| True|\n|1018|     Shelly|   Briggs|   3514 Leslie Vista|1986-09-02|2021-07-25|      null|False|\n|1019|       Tina|   Garcia|00348 Brandi Park...|1997-05-03|2021-07-10|2022-01-01|False|\n+----+-----------+---------+--------------------+----------+----------+----------+-----+\nonly showing top 20 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<h3>stations_table</h3>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<h3>stations_table</h3>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+------------+--------------------+------------------+------------------+\n",
       "         _c0|                 _c1|               _c2|               _c3|\n",
       "+------------+--------------------+------------------+------------------+\n",
       "         525|Glenwood Ave &amp; To...|         42.012701|-87.66605799999999|\n",
       "KA1503000012|  Clark St &amp; Lake St| 41.88579466666667|-87.63110066666668|\n",
       "         637|Wood St &amp; Chicago...|         41.895634|        -87.672069|\n",
       "       13216|  State St &amp; 33rd St|        41.8347335|       -87.6258275|\n",
       "       18003|Fairbanks St &amp; Su...| 41.89580766666667|-87.62025316666669|\n",
       "KP1705001026|LaSalle Dr &amp; Huro...|         41.894877|        -87.632326|\n",
       "       13253|Lincoln Ave &amp; Wav...|         41.948797|        -87.675278|\n",
       "KA1503000044|Rush St &amp; Hubbard St|         41.890173|-87.62618499999999|\n",
       "KA1504000140|Winchester Ave &amp; ...| 41.92403733333333|-87.67641483333334|\n",
       "TA1305000032|Clinton St &amp; Madi...|         41.882242|-87.64106600000001|\n",
       "TA1306000012| Wells St &amp; Huron St| 41.89475366666667|-87.63440200000001|\n",
       "       13133|Damen Ave &amp; Cortl...|41.915983000000004|        -87.677335|\n",
       "      SL-005|Indiana Ave &amp; Roo...|         41.867888|        -87.623041|\n",
       "       13235|Southport Ave &amp; W...|          41.94815|         -87.66394|\n",
       "TA1307000139| MLK Jr Dr &amp; 29th St|         41.842052|           -87.617|\n",
       "TA1305000009|Clark St &amp; Ida B ...|     41.8759326655|-87.63058453549999|\n",
       "       13276|Stockton Dr &amp; Wri...|        41.9313455|-87.63869133333333|\n",
       "TA1307000107|Sheridan Rd &amp; Mon...|          41.96167|         -87.65464|\n",
       "       13193|Larrabee St &amp; Web...|         41.921822|-87.64414000000001|\n",
       "KA1503000072|Wacker Dr &amp; Washi...|         41.883132|        -87.637321|\n",
       "+------------+--------------------+------------------+------------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+------------+--------------------+------------------+------------------+\n|         _c0|                 _c1|               _c2|               _c3|\n+------------+--------------------+------------------+------------------+\n|         525|Glenwood Ave &amp; To...|         42.012701|-87.66605799999999|\n|KA1503000012|  Clark St &amp; Lake St| 41.88579466666667|-87.63110066666668|\n|         637|Wood St &amp; Chicago...|         41.895634|        -87.672069|\n|       13216|  State St &amp; 33rd St|        41.8347335|       -87.6258275|\n|       18003|Fairbanks St &amp; Su...| 41.89580766666667|-87.62025316666669|\n|KP1705001026|LaSalle Dr &amp; Huro...|         41.894877|        -87.632326|\n|       13253|Lincoln Ave &amp; Wav...|         41.948797|        -87.675278|\n|KA1503000044|Rush St &amp; Hubbard St|         41.890173|-87.62618499999999|\n|KA1504000140|Winchester Ave &amp; ...| 41.92403733333333|-87.67641483333334|\n|TA1305000032|Clinton St &amp; Madi...|         41.882242|-87.64106600000001|\n|TA1306000012| Wells St &amp; Huron St| 41.89475366666667|-87.63440200000001|\n|       13133|Damen Ave &amp; Cortl...|41.915983000000004|        -87.677335|\n|      SL-005|Indiana Ave &amp; Roo...|         41.867888|        -87.623041|\n|       13235|Southport Ave &amp; W...|          41.94815|         -87.66394|\n|TA1307000139| MLK Jr Dr &amp; 29th St|         41.842052|           -87.617|\n|TA1305000009|Clark St &amp; Ida B ...|     41.8759326655|-87.63058453549999|\n|       13276|Stockton Dr &amp; Wri...|        41.9313455|-87.63869133333333|\n|TA1307000107|Sheridan Rd &amp; Mon...|          41.96167|         -87.65464|\n|       13193|Larrabee St &amp; Web...|         41.921822|-87.64414000000001|\n|KA1503000072|Wacker Dr &amp; Washi...|         41.883132|        -87.637321|\n+------------+--------------------+------------------+------------------+\nonly showing top 20 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for table_name, table in dataframes.items():\n",
    "    displayHTML(f\"<h3>{table_name}_table</h3>\")  # Display the table name as a title\n",
    "    table.show() # Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da4ea071-a6ec-431d-ba38-a5e861be2af0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---+----------+---+----+\n",
       "_c0|       _c1|_c2| _c3|\n",
       "+---+----------+---+----+\n",
       "  1|2019-05-01|9.0|1000|\n",
       "  2|2019-06-01|9.0|1000|\n",
       "  3|2019-07-01|9.0|1000|\n",
       "  4|2019-08-01|9.0|1000|\n",
       "  5|2019-09-01|9.0|1000|\n",
       "+---+----------+---+----+\n",
       "only showing top 5 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+---+----------+---+----+\n|_c0|       _c1|_c2| _c3|\n+---+----------+---+----+\n|  1|2019-05-01|9.0|1000|\n|  2|2019-06-01|9.0|1000|\n|  3|2019-07-01|9.0|1000|\n|  4|2019-08-01|9.0|1000|\n|  5|2019-09-01|9.0|1000|\n+---+----------+---+----+\nonly showing top 5 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "payment_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73f82cad-3c42-4997-8640-4b1e761e6570",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Formatting the columns to reflect the schema design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cf46672-81c8-4e37-91e2-688295e32cdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def format_columns(table_path: str, column_rename_dict: dict, column_type_dict: dict) -> None:\n",
    "    \"\"\"\n",
    "    Formats columns in a Spark table by renaming and casting types.\n",
    "\n",
    "    Args:\n",
    "        table_path (str): The path to the table.\n",
    "        column_rename_dict (dict): A dictionary mapping old column names to new column names.\n",
    "        column_type_dict (dict): A dictionary mapping column names to their new types.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Read the table\n",
    "    df = spark.read.table(table_path)\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.select([col(c).alias(column_rename_dict.get(c, c)) for c in df.columns])\n",
    "\n",
    "    # Cast column types\n",
    "    df = df.select([col(c).cast(column_type_dict.get(c, df.schema[c].dataType)) for c in df.columns])\n",
    "\n",
    "    # Write the transformed DataFrame back to the table\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", True).saveAsTable(table_path)\n",
    "\n",
    "\n",
    "\n",
    "# Column renaming and type definitions\n",
    "columns_types = {\n",
    "    'payments': ({'_c0': 'payment_id', '_c1': 'date_id', '_c2': 'amount', '_c3': 'rider_id'}, {'payment_id': 'int', 'amount': 'decimal', 'date_id': 'date', 'rider_id': 'int'}),\n",
    "    'trips': ({'_c0': 'trip_id', '_c1': 'rideable_type', '_c2': 'started_at', '_c3': 'ended_at', '_c4': 'start_station_id', '_c5': 'end_station_id', '_c6': 'rider_id'}, {'trip_id': 'string', 'rideable_type': 'string', 'started_at': 'timestamp', 'ended_at': 'timestamp', 'start_station_id': 'string', 'end_station_id': 'string', 'rider_id': 'int'}),\n",
    "    'riders': ({'_c0': 'rider_id', '_c1': 'first', '_c2': 'last', '_c3': 'address', '_c4': 'birthday', '_c5': 'account_start_date', '_c6': 'account_end_date', '_c7': 'is_member'}, {'rider_id': 'int', 'first': 'string', 'last': 'string', 'address': 'string', 'birthday': 'date', 'account_start_date': 'date', 'account_end_date': 'date', 'is_member': 'boolean'}),\n",
    "    'stations': ({'_c0': 'station_id', '_c1': 'name', '_c2': 'latitude', '_c3': 'longitude'}, {'station_id': 'string', 'name': 'string', 'latitude': 'float', 'longitude': 'float'})\n",
    "}\n",
    "\n",
    "# Apply transformations for each table\n",
    "for table, (columns, types) in columns_types.items():\n",
    "    format_columns(table, columns, types)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5b4a9db-e9d2-4c39-a328-d0df0ea87098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Adding columns to address business outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a641053-ef9c-4ee0-980b-c936cbf307dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read tables\n",
    "dataframes = {\n",
    "    'trips': spark.read.table('trips'),\n",
    "    'riders': spark.read.table('riders'),\n",
    "    'payments': spark.read.table('payments')\n",
    "}\n",
    "\n",
    "# Calculate trip duration and time_id\n",
    "dataframes['trips'] = dataframes['trips'].withColumn(\"duration\", (col(\"ended_at\") - col(\"started_at\")).cast(\"long\")) \\\n",
    "                                         .withColumn(\"time_id\", date_trunc(\"hour\", col(\"started_at\")))\n",
    "\n",
    "# Calculate age at account start\n",
    "dataframes['riders'] = dataframes['riders'].withColumn(\"age_at_account_start\", (datediff(col(\"account_start_date\"), col(\"birthday\")) / 365).cast(\"int\"))\n",
    "\n",
    "# Write updated rider data\n",
    "dataframes['riders'].write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", True).saveAsTable('riders')\n",
    "\n",
    "# List rider columns excluding 'rider_id'\n",
    "rider_columns = [col for col in dataframes['riders'].columns if col != 'rider_id']\n",
    "\n",
    "# Join trip and rider data, calculate age at ride time\n",
    "dataframes['trips'] = dataframes['trips'].join(dataframes['riders'].select('rider_id', 'birthday'), on='rider_id', how='inner') \\\n",
    "                                         .withColumn(\"age_at_ride_time\", (datediff(to_date(col(\"started_at\")), col(\"birthday\")) / 365).cast(\"int\")) \\\n",
    "                                         .select('trip_id', 'duration', 'rideable_type', 'age_at_ride_time', 'started_at', 'ended_at', 'start_station_id', 'end_station_id', 'time_id', 'rider_id')\n",
    "\n",
    "# Write updated trip data\n",
    "dataframes['trips'].write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", True).saveAsTable('trips')\n",
    "\n",
    "# Write payment data\n",
    "dataframes['payments'].select('payment_id', 'amount', 'date_id', 'rider_id').write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", True).saveAsTable('payments')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a56943bd-0627-4dda-a953-3506e6257ef9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Date Dimensions\n",
    "Separate date dimension tables will be created for payment and trip data due to differences in their time granularity:\n",
    "\n",
    "The trip date dimension captures time-of-day info (morning, afternoon, evening, night) at an hourly level. The payment date dimension focuses on spending trends by month, quarter, and year at a daily level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b78804d3-1284-4b6e-9049-352e14bac62c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read and cache tables\n",
    "payment_df, trip_df = (spark.read.table('payments').cache(), spark.read.table('trips').cache())\n",
    "\n",
    "# Get min and max dates for payment and trip\n",
    "payment_min_date, payment_max_date = payment_df.select(min('date_id'), max('date_id')).first()\n",
    "trip_min_date, trip_max_date = trip_df.select(min('time_id'), max('time_id')).first()\n",
    "\n",
    "# Log date ranges\n",
    "print(f\"Trip Dates: {trip_min_date} to {trip_max_date}\")\n",
    "print(f\"Payment Dates: {payment_min_date} to {payment_max_date}\")\n",
    "\n",
    "# Create date and time sequences\n",
    "sequences = [\n",
    "    spark.sql(f\"SELECT explode(sequence(to_date('{payment_min_date}'), to_date('{payment_max_date}'), INTERVAL 1 DAY)) AS date\").createOrReplaceTempView('payment_dates_view'),\n",
    "    spark.sql(f\"SELECT explode(sequence(to_timestamp('{trip_min_date}'), to_timestamp('{trip_max_date}'), INTERVAL 1 HOUR)) AS time\").createOrReplaceTempView('trip_dates_view')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b4ba282-101d-49ca-bd88-f1e7ad6acca3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql SELECT * FROM trip_dates_view LIMIT 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ca6bb6c-1d78-4a05-a896-a3ea617bf2e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trip_dates_query = f\"\"\"\n",
    "SELECT\n",
    "    time AS time_id,\n",
    "    dayofweek(time) AS day_of_week,\n",
    "    CASE \n",
    "        WHEN hour(time) BETWEEN 5 AND 11 THEN 'morning'\n",
    "        WHEN hour(time) BETWEEN 12 AND 16 THEN 'afternoon'\n",
    "        WHEN hour(time) BETWEEN 17 AND 21 THEN 'evening'\n",
    "        ELSE 'night'\n",
    "    END AS time_of_day\n",
    "FROM trip_dates_view\n",
    "ORDER BY time\n",
    "\"\"\"\n",
    "\n",
    "trip_dates = spark.sql(trip_dates_query)\n",
    "trip_dates.write.format('delta').mode('overwrite').saveAsTable('trip_dates')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41d4f3a2-d4a1-40a0-a9b6-3e44a4490957",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the SQL query  for payment dates\n",
    "payment_dates_query = f\"\"\"\n",
    "SELECT\n",
    "    date AS date_id,\n",
    "    month(date) AS month,\n",
    "    quarter(date) AS quarter,\n",
    "    year(date) AS year\n",
    "FROM payment_dates_view\n",
    "ORDER BY date\n",
    "\"\"\"\n",
    "\n",
    "payment_dates = spark.sql(payment_dates_query)\n",
    "payment_dates.write.format('delta').mode('overwrite').saveAsTable('payment_dates')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1492c8ae-d8dc-41e7-b185-c6a9bbbd573f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Business Questions to Address\n",
    "\n",
    "- Analyze how much time is spent per ride\n",
    "  * Based on date and time factors such as day of week and time of day\n",
    "  * Based on which station is the starting and / or ending station\n",
    "  * Based on age of the rider at time of the ride\n",
    "  * Based on whether the rider is a member or a casual rider\n",
    "- Analyze how much money is spent\n",
    "  * Per month, quarter, year\n",
    "  * Per member, based on the age of the rider at account start\n",
    "- EXTRA CREDIT - Analyze how much money is spent per member\n",
    "  * Based on how many rides the rider averages per month\n",
    "  * Based on how many minutes the rider spends on a bike per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce04ed99-88e8-4284-a07b-c179492b4612",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the fact and dimension tables\n",
    "tables = ['payments', 'trips', 'riders', 'stations', 'trip_dates', 'payment_dates']\n",
    "payment_df, trip_df, rider_df, station_df, trip_date_df, payment_date_df = [spark.read.table(table) for table in tables]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30fdfaa9-4829-409d-b1a9-e60f5ce3f9cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Trip Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "111ba6e9-1cd9-4e74-a866-d0eb21d7604d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def analyze_trip_data(df: DataFrame, group_col: str, agg_func: Column, alias: str) -> None:\n",
    "    \"\"\"\n",
    "    Analyzes trip data by joining with the trip date DataFrame and applying an aggregation function.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame containing trip data.\n",
    "        group_col (str): The column to group by.\n",
    "        agg_func (Column): The aggregation function to apply (e.g., avg, sum).\n",
    "        alias (str): The alias for the aggregated column.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df.join(trip_date_df, 'time_id')\\\n",
    "        .groupBy(group_col)\\\n",
    "        .agg(agg_func('duration').alias(alias))\\\n",
    "        .orderBy(alias, ascending=False)\\\n",
    "        .show()\n",
    "\n",
    "\n",
    "# Analyze how much time is spent per ride on average based on day of week\n",
    "analyze_trip_data(trip_df, 'day_of_week', avg, 'duration_in_seconds_avg')\n",
    "\n",
    "# Analyze how much time is spent per ride in total based on day of week\n",
    "analyze_trip_data(trip_df, 'day_of_week', sum, 'duration_in_seconds_sum')\n",
    "\n",
    "# Analyze how much time is spent per ride on average based on time of day\n",
    "analyze_trip_data(trip_df, 'time_of_day', avg, 'duration_in_seconds_avg')\n",
    "\n",
    "# Analyze how much time is spent per ride in total based on time of day\n",
    "analyze_trip_data(trip_df, 'time_of_day', sum, 'duration_in_seconds_sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0134da3a-dbd9-42c6-a4dd-404931621940",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def analyze_duration(df: DataFrame, group_col: str, agg_func: Column, alias: str) -> None:\n",
    "    \"\"\"\n",
    "    Analyzes duration data by grouping and applying an aggregation function.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame containing duration data.\n",
    "        group_col (str): The column to group by.\n",
    "        agg_func (Column): The aggregation function to apply (e.g., avg, sum).\n",
    "        alias (str): The alias for the aggregated column.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df.groupBy(group_col)\\\n",
    "      .agg(agg_func('duration').alias(alias))\\\n",
    "      .orderBy(alias, ascending=False)\\\n",
    "      .show()\n",
    "\n",
    "# Avg and total duration per ride by start station\n",
    "analyze_duration(trip_df, 'start_station_id', avg, 'duration_in_seconds_avg')\n",
    "analyze_duration(trip_df, 'start_station_id', sum, 'duration_in_seconds_sum')\n",
    "\n",
    "# Avg and total duration per ride by end station\n",
    "analyze_duration(trip_df, 'end_station_id', avg, 'duration_in_seconds_avg')\n",
    "analyze_duration(trip_df, 'end_station_id', sum, 'duration_in_seconds_sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b689e0a7-52e4-43ed-ad04-4728ffd3ed5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import Column\n",
    "\n",
    "def analyze_duration_by_age(df: DataFrame, group_col: str, agg_func: Column, alias: str) -> None:\n",
    "    \"\"\"\n",
    "    Analyzes duration data by joining with the rider DataFrame, grouping by the specified column, and applying an aggregation function.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame containing duration data.\n",
    "        group_col (str): The column to group by.\n",
    "        agg_func (Column): The aggregation function to apply (e.g., avg, sum).\n",
    "        alias (str): The alias for the aggregated column.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df.join(rider_df, df.rider_id == rider_df.rider_id)\\\n",
    "      .groupBy(group_col)\\\n",
    "      .agg(agg_func('duration').alias(alias))\\\n",
    "      .orderBy(alias, ascending=False)\\\n",
    "      .show()\n",
    "\n",
    "\n",
    "# Avg and total duration by age at account start\n",
    "analyze_duration_by_age(trip_df, 'age_at_account_start', avg, 'duration_in_seconds_avg')\n",
    "analyze_duration_by_age(trip_df, 'age_at_account_start', sum, 'duration_in_seconds_sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5803bc12-edb6-47ea-a0ab-b34e54834e96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def analyze_duration_by_membership(df: DataFrame, group_col: str, agg_func: Column, alias: str) -> None:\n",
    "    \"\"\"\n",
    "    Analyzes duration data by joining with the rider DataFrame, grouping by membership status, and applying an aggregation function.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame containing duration data.\n",
    "        group_col (str): The column to group by.\n",
    "        agg_func (Column): The aggregation function to apply (e.g., avg, sum).\n",
    "        alias (str): The alias for the aggregated column.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df.join(rider_df, 'rider_id')\\\n",
    "      .groupBy(group_col)\\\n",
    "      .agg(agg_func('duration').alias(alias))\\\n",
    "      .orderBy(alias, ascending=False)\\\n",
    "      .show()\n",
    "\n",
    "\n",
    "# Avg and total duration by rider membership\n",
    "analyze_duration_by_membership(trip_df, 'is_member', avg, 'duration_in_seconds_avg')\n",
    "analyze_duration_by_membership(trip_df, 'is_member', sum, 'duration_in_seconds_sum')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a362792-1768-4999-832d-c5a2426e01bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Payment Table Queries For Analyzing Payment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23ea5766-5f3a-405c-99c4-9909ddc8d2f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def analyze_payment_data(df: DataFrame, group_col: str, agg_funcs: list, aliases: list):\n",
    "    for agg_func, alias in zip(agg_funcs, aliases):\n",
    "        df.join(payment_date_df, 'date_id')\\\n",
    "          .groupBy(group_col)\\\n",
    "          .agg(agg_func('amount').alias(alias))\\\n",
    "          .orderBy(alias, ascending=False)\\\n",
    "          .show()\n",
    "\n",
    "# Aggregation functions and their aliases\n",
    "agg_funcs = [sum, avg]\n",
    "aliases = ['amount_sum', 'amount_avg']\n",
    "\n",
    "# Analyze spending by different time periods\n",
    "for group_col in ['month', 'quarter', 'year']:\n",
    "    analyze_payment_data(payment_df, group_col, agg_funcs, aliases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "544763ab-fb04-44c9-8493-9d70ca0eb828",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def analyze_member_payment_data(df: DataFrame, group_col: str, agg_func: Column, alias: str) -> None:\n",
    "    \"\"\"\n",
    "    Analyzes payment data for members by joining with the rider DataFrame, \n",
    "    grouping by the specified column, and applying an aggregation function.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame containing payment data.\n",
    "        group_col (str): The column to group by.\n",
    "        agg_func (Column): The aggregation function to apply (e.g., avg, sum).\n",
    "        alias (str): The alias for the aggregated column.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df.join(rider_df, 'rider_id')\\\n",
    "      .where(rider_df.is_member == True)\\\n",
    "      .groupBy(group_col)\\\n",
    "      .agg(agg_func('amount').alias(alias))\\\n",
    "      .orderBy(alias, ascending=False)\\\n",
    "      .show()\n",
    "\n",
    "# Agg functions and their aliases\n",
    "agg_funcs = [avg, sum]\n",
    "aliases = ['amount_avg', 'amount_sum']\n",
    "\n",
    "# Analyze spending by members by age at account start\n",
    "for agg_func, alias in zip(agg_funcs, aliases):\n",
    "    analyze_member_payment_data(payment_df, 'age_at_account_start', agg_func, alias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbda4068-daea-4260-a25b-fdabc782c5e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Extra Credit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e0539bf-215a-4a7e-a872-7c79819825cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Avg spending per member by monthly ride count\n",
    "trip_df.join(payment_df, 'rider_id')\\\n",
    "    .select('rider_id', 'time_id', 'amount', 'trip_id')\\\n",
    "    .join(rider_df.where(rider_df.is_member == True), 'rider_id')\\\n",
    "    .withColumn('month', month('time_id'))\\\n",
    "    .groupby('rider_id', 'month')\\\n",
    "    .agg(avg('amount').alias('avg_amount'), count('trip_id').alias('num_rides'))\\\n",
    "    .orderBy('num_rides', ascending=False)\\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fb29adc-8e9a-4561-9066-6f993e58c333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Avg spending per member by monthly bike usage\n",
    "trip_df.join(rider_df, 'rider_id')\\\n",
    "    .join(payment_df, 'rider_id')\\\n",
    "    .filter(rider_df.is_member)\\\n",
    "    .withColumn('month', month('time_id'))\\\n",
    "    .withColumn('minutes', (trip_df.duration / 60).cast('int'))\\\n",
    "    .groupBy('rider_id', 'minutes', 'month')\\\n",
    "    .agg(\n",
    "        avg('amount').alias('avg_amount'),\n",
    "        avg('duration').alias('avg_duration')\n",
    "    )\\\n",
    "    .orderBy('avg_duration', ascending=False)\\\n",
    "    .show()\n",
    "\n",
    "# Investigate extended usage of a specific rider\n",
    "trip_df.filter(trip_df.rider_id == 1088)\\\n",
    "    .select('rider_id', 'started_at', 'ended_at', 'duration')\\\n",
    "    .orderBy('duration', ascending=False)\\\n",
    "    .show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 254777733165727,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "adls_bikeshare_project_IsmaelDawuda",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
